{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f8d98c-4286-4392-b1fd-e885adf23ab9",
   "metadata": {},
   "source": [
    "### Improving the Streamlit app for face detection using Viola-Jones algorithm of the example of the content\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Add instructions to the Streamlit app interface to guide the user on how to use the app.\n",
    "\n",
    "Add a feature to save the images with detected faces on the user's device.\n",
    "\n",
    "Add a feature to allow the user to choose the color of the rectangles drawn around the detected faces.\n",
    "\n",
    "Add a feature to adjust the minNeighbors parameter in the face_cascade.detectMultiScale() function.\n",
    "\n",
    "Add a feature to adjust the scaleFactor parameter in the face_cascade.detectMultiScale() function.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "Use the st.write() or st.markdown() functions to add instructions to the interface.\n",
    "\n",
    "Use the cv2.imwrite() function to save the images.\n",
    "\n",
    "Use the st.color_picker() function to allow the user to choose the color of the rectangles.\n",
    "\n",
    "Use the st.slider() function to allow the user to adjust the minNeighbors parameter.\n",
    "\n",
    "Use the st.slider() function to allow the user to adjust the scaleFactor parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c49d08-95f0-4c6a-bfb0-5fca27d1e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_content = '''\n",
    "\n",
    "# Import required libraries\n",
    "import cv2  # OpenCV for real-time computer vision tasks\n",
    "import streamlit as st  # Streamlit for web app interface\n",
    "from PIL import Image  # For handling image operations\n",
    "import numpy as np  # For numerical computations\n",
    "import os  # For interacting with the operating system\n",
    "import time\n",
    "\n",
    "# Load the Haar Cascade Classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(r'Downloads/haarcascade_frontalface_default (1).xml')\n",
    "# The XML file contains the pre-trained model for detecting faces.\n",
    "\n",
    "# Step 1: Function to detect faces from webcam feed\n",
    "def detect_faces(scaleFactor, minNeighbors, color_choice):\n",
    "    cap = cv2.VideoCapture(0)  # Opens the default webcam (0 refers to the default device)\n",
    "    stframe = st.empty()  # Placeholder for displaying the webcam video in Streamlit\n",
    "    saved = False  # Initialize a saved flag for the save button functionality\n",
    "\n",
    "    # Check if stop detection flag exists in session state, initialize if not\n",
    "    if \"stop_detection\" not in st.session_state:\n",
    "        st.session_state.stop_detection = False\n",
    "\n",
    "    # Checkbox to stop face detection\n",
    "    stop_detection = st.checkbox(\"Stop Face Detection\", key=\"stop_detection_checkbox\")\n",
    "\n",
    "    while not st.session_state.stop_detection:  # Loop until stop detection is triggered\n",
    "        ret, frame = cap.read()  # Capture each frame\n",
    "        if not ret:  # If the frame is not captured successfully\n",
    "            st.error(\"Failed to capture image from webcam.\")  # Display an error message\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to grayscale (face detection works better on grayscale images)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces in the grayscale image\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=(30, 30))\n",
    "        \n",
    "        # Convert the selected color from hex format (RGB) to BGR for OpenCV\n",
    "        color_rgb = tuple(int(color_choice.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "        color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # Reverse the RGB to BGR\n",
    "\n",
    "        \n",
    "        # Draw rectangles around detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color_bgr, 2)  # Draw rectangle on each detected face\n",
    "        \n",
    "        # Display the current frame with detected faces in the Streamlit app\n",
    "        stframe.image(frame, channels=\"BGR\", use_column_width=True)\n",
    "        \n",
    "        # Create a unique key for each save button using the current timestamp\n",
    "        button_key = f\"save_image_{str(time.time())}\"\n",
    "        \n",
    "        # Button to save the image with detected faces\n",
    "        if st.button(\"Save Image with Detected Faces\", key=button_key) and not saved:\n",
    "            cv2.imwrite(\"detected_faces.png\", frame)  # Save the current frame as an image\n",
    "            st.success(\"Image saved as detected_faces.png\")  # Display success message\n",
    "            saved = True  # Set the flag to prevent multiple saves\n",
    "        \n",
    "        # Update the stop detection flag if the checkbox is checked\n",
    "        if stop_detection:\n",
    "            st.session_state.stop_detection = True\n",
    "\n",
    "    cap.release()  # Release the webcam resource\n",
    "    cv2.destroyAllWindows()  # Close any OpenCV windows\n",
    "\n",
    "# Step 2: Define the Streamlit app interface\n",
    "def app():\n",
    "    st.title(\"Face Detection App using Viola-Jones Algorithm\")  # Title of the app\n",
    "    \n",
    "    # Instructions for the user\n",
    "    st.markdown(\"\"\"\n",
    "    ### Instructions:\n",
    "    1. Use the **slider** below to adjust the `scaleFactor` and `minNeighbors` parameters for face detection.\n",
    "    2. Choose the **color** of the rectangle that will be drawn around the detected faces.\n",
    "    3. Press the **'Detect Faces'** button to start detecting faces using your webcam.\n",
    "    4. Optionally, save the detected face image by pressing the **'Save Image with Detected Faces'** button.\n",
    "    5. Use the checkbox to **stop detection**.\n",
    "    \"\"\")\n",
    "    \n",
    "    # Slider for adjusting the `scaleFactor` (resizing of the image for detection)\n",
    "    scaleFactor = st.slider(\"Adjust scaleFactor (Image resizing)\", min_value=1.01, max_value=2.0, value=1.1, step=0.01)\n",
    "    \n",
    "    # Slider for adjusting `minNeighbors` (controls detection sensitivity)\n",
    "    minNeighbors = st.slider(\"Adjust minNeighbors (Detection sensitivity)\", min_value=3, max_value=10, value=5, step=1)\n",
    "    \n",
    "    # Color picker for the rectangle that will highlight detected faces\n",
    "    color_choice = st.color_picker(\"Pick a color for the detection rectangle\", \"#FF0000\")\n",
    "    \n",
    "    # Button to start face detection\n",
    "    if st.button(\"Detect Faces\", key=\"detect_faces\"):\n",
    "        detect_faces(scaleFactor, minNeighbors, color_choice)  # Call the face detection function with parameters\n",
    "\n",
    "# Step 3: Run the Streamlit app\n",
    "if __name__ == \"__main__\":  # If the script is run directly\n",
    "    app()  # Run the app\n",
    "    \n",
    "'''\n",
    "\n",
    "# Open a file in write mode and save the code content\n",
    "with open('face_detection_app_2.py', 'w') as file:\n",
    "    file.write(code_content)\n",
    "print(\"The Python script has been successfully saved to 'face_detection_app.py'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
